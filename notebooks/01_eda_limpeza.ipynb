{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8e0796",
   "metadata": {},
   "source": [
    "# üìò Notebook 01 ‚Äî EDA & Prepara√ß√£o do Dataset (Renda x Im√≥veis x D√≠vidas)\n",
    "\n",
    "Projeto: **Clusteriza√ß√£o em 3D com K-Means**  \n",
    "Disciplina: **Aprendizado de M√°quina N√£o Supervisionado** ‚Äî Senac DF  \n",
    "Autores: **Anderson de Matos Guimar√£es, Renan Ost, Gustavo Stefano Thomazinho**\n",
    "\n",
    "**Objetivo deste notebook**  \n",
    "Explorar o dataset bruto de **Distribui√ß√£o de Renda por Centis** (IRPF), entender o neg√≥cio, selecionar **3 vari√°veis cont√≠nuas** e produzir um dataset **limpo e padronizado** para o Notebook 02 (clusteriza√ß√£o e visualiza√ß√£o 3D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f7808",
   "metadata": {},
   "source": [
    "## üéØ Escopo & Entreg√°veis\n",
    "\n",
    "**Vamos:**\n",
    "1. Carregar e validar o CSV bruto.  \n",
    "2. Inspecionar colunas, tipos, nulos, duplicatas e consist√™ncia.  \n",
    "3. Documentar o **dicion√°rio de dados** (vis√£o de neg√≥cio).  \n",
    "4. Definir a **amostragem reprodut√≠vel** (300‚Äì500 linhas) com crit√©rios claros.  \n",
    "5. Selecionar e preparar as **3 vari√°veis**:\n",
    "   - `rtb_soma_centil` (renda),\n",
    "   - `bens_imoveis` (patrim√¥nio),\n",
    "   - `dividas_onus` (endividamento).\n",
    "6. Tratar outliers e zeros estruturais quando necess√°rio (sem distorcer a realidade).  \n",
    "7. Escalonar (opcional) e **salvar** o dataset tratado (+ `metadata.json`).  \n",
    "\n",
    "**Sa√≠das:**\n",
    "- `data/processed/distribuicao-renda-3vars.csv`  \n",
    "- `data/processed/distribuicao-renda-3vars.metadata.json`  \n",
    "- Gr√°ficos e anota√ß√µes que justificam as decis√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a597719",
   "metadata": {},
   "source": [
    "## ‚úÖ Crit√©rios do Professor (como atendemos)\n",
    "\n",
    "- **Entradas (300‚Äì500)** ‚Üí definiremos uma **amostra reprodut√≠vel** com base em (ano, entes federativos, centis).  \n",
    "- **Dados granulares** ‚Üí centis (100 cortes por distribui√ß√£o de RTB) garantem granularidade.  \n",
    "- **Num√©ricos cont√≠nuos** ‚Üí valores monet√°rios (R$) para as 3 vari√°veis.  \n",
    "- **Exatamente 3 vari√°veis** ‚Üí renda, patrim√¥nio (im√≥veis) e d√≠vidas (3D pronto).  \n",
    "- **Notebook estilo IDEB** ‚Üí manteremos se√ß√µes claras, decis√µes justificadas e, no 02, poderemos comparar diferentes *k* (e opcionalmente usar dois anos se for relevante)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618a79b",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Fonte de Dados, Licen√ßa e Paths\n",
    "\n",
    "- **Fonte oficial**: Receita Federal ‚Äî Distribui√ß√£o de Renda por Centis.  \n",
    "- **Arquivo bruto**: `data/raw/distribuicao-renda.csv`  \n",
    "- **Arquivo tratado (3 vari√°veis)**: `data/processed/distribuicao-renda-3vars.csv`\n",
    "\n",
    "> Observa√ß√£o: trabalharemos com unidades conforme o arquivo (muitos campos est√£o em **R$ milh√µes**). Faremos padroniza√ß√£o de nomes e registraremos as unidades no metadado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b5fb6",
   "metadata": {},
   "source": [
    "## üè¢ Entendimento do Neg√≥cio (resumo)\n",
    "\n",
    "O dataset agrega informa√ß√µes de declara√ß√µes de **IRPF** por **centis de renda tribut√°vel bruta (RTB)**.  \n",
    "Cada linha representa um **grupo** (centil) para um **ente federativo** em um **ano**.  \n",
    "As colunas trazem somat√≥rios de rendimentos, bens/direitos, despesas dedut√≠veis, d√≠vidas, etc.\n",
    "\n",
    "**Hip√≥teses de leitura econ√¥mica (para orientar a an√°lise):**\n",
    "- `rtb_soma_centil` aproxima **capacidade de gera√ß√£o de renda** do grupo.  \n",
    "- `bens_imoveis` aproxima **acumula√ß√£o patrimonial** est√°vel.  \n",
    "- `dividas_onus` aproxima **alavancagem/endividamento**.  \n",
    "\n",
    "Essas tr√™s dimens√µes juntas formam um **espa√ßo 3D** que deveria segregar perfis de grupos (baixa renda com baixa riqueza e baixa d√≠vida vs. alta renda com alta riqueza e d√≠vida vari√°vel, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb907d",
   "metadata": {},
   "source": [
    "## üìñ Dicion√°rio de Dados (campos relevantes ao projeto)\n",
    "\n",
    "| Coluna original (exemplo)                 | Nome padronizado        | Tipo      | Unidade         | Observa√ß√£o de neg√≥cio |\n",
    "|-------------------------------------------|-------------------------|-----------|-----------------|-----------------------|\n",
    "| Ano-calend√°rio                            | `ano`                   | int       | ano             | Ano da declara√ß√£o     |\n",
    "| Ente Federativo                           | `uf`                    | string    | ‚Äî               | Estado/Agregado       |\n",
    "| Centil                                    | `centil`                | float     | 1‚Äì100           | Corte por RTB         |\n",
    "| Rend. Trib. ‚Äî Soma da RTB do Centil       | `rtb_soma_centil`       | float     | R$ milh√µes      | **Renda** (capacidade)|\n",
    "| Bens e Direitos ‚Äî Im√≥veis                 | `bens_imoveis`          | float     | R$ milh√µes      | **Patrim√¥nio**        |\n",
    "| D√≠vidas e √înus                            | `dividas_onus`          | float     | R$ milh√µes      | **Endividamento**     |\n",
    "\n",
    "> Notas:\n",
    "> - Confirmaremos nomes exatos das colunas do CSV bruto e mapearemos para os padronizados acima.  \n",
    "> - Se necess√°rio, convertendo v√≠rgulas decimais e removendo formata√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, seed e paths (corrigidos para notebook em /notebooks)\n",
    "from __future__ import annotations\n",
    "import os, json, math, textwrap, re, sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.float_format\", lambda v: f\"{v:,.3f}\")\n",
    "\n",
    "# Paths\n",
    "ROOT = Path(\"..\").resolve()  # sobe um n√≠vel a partir de /notebooks\n",
    "DATA_RAW = ROOT / \"data\" / \"raw\" / \"distribuicao-renda.csv\"\n",
    "DATA_PROCESSED_DIR = ROOT / \"data\" / \"processed\"\n",
    "DATA_PROCESSED = DATA_PROCESSED_DIR / \"distribuicao-renda-3vars.csv\"\n",
    "METADATA = DATA_PROCESSED_DIR / \"distribuicao-renda-3vars.metadata.json\"\n",
    "FIG_DIR = ROOT / \"reports\" / \"figures\"\n",
    "for p in [DATA_PROCESSED_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FALLBACK_FILE = Path(\"/mnt/data/distribuicao-renda.csv\")\n",
    "if not DATA_RAW.exists() and FALLBACK_FILE.exists():\n",
    "    print(f\"[INFO] Usando fallback: {FALLBACK_FILE}\")\n",
    "    DATA_RAW = FALLBACK_FILE\n",
    "\n",
    "print(\"ROOT        :\", ROOT)\n",
    "print(\"DATA_RAW    :\", DATA_RAW)\n",
    "print(\"PROCESSED   :\", DATA_PROCESSED)\n",
    "print(\"FIG_DIR     :\", FIG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_br(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Leitura robusta para CSV com poss√≠veis varia√ß√µes:\n",
    "    - separador ',' ou ';'\n",
    "    - decimal '.' ou ','\n",
    "    - encoding 'utf-8' ou 'latin-1'\n",
    "    Retorna o DataFrame lido com detec√ß√£o autom√°tica.\n",
    "    \"\"\"\n",
    "    trials = [\n",
    "        dict(sep=\";\", decimal=\",\", encoding=\"utf-8\", engine=\"python\"),\n",
    "        dict(sep=\",\", decimal=\",\", encoding=\"utf-8\", engine=\"python\"),\n",
    "        dict(sep=\";\", decimal=\".\", encoding=\"utf-8\", engine=\"python\"),\n",
    "        dict(sep=\",\", decimal=\".\", encoding=\"utf-8\", engine=\"python\"),\n",
    "        dict(sep=\";\", decimal=\",\", encoding=\"latin-1\", engine=\"python\"),\n",
    "        dict(sep=\",\", decimal=\",\", encoding=\"latin-1\", engine=\"python\"),\n",
    "    ]\n",
    "    last_err = None\n",
    "    for opts in trials:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, **opts)\n",
    "            if df.shape[1] == 1:\n",
    "                last_err = RuntimeError(\"prov√°vel separador incorreto (1 coluna)\")\n",
    "                continue\n",
    "            print(f\"[OK] Leitura com par√¢metros: {opts}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Falha ao ler {filepath}: {last_err}\")\n",
    "\n",
    "def snake(s: str) -> str:\n",
    "    s2 = re.sub(r\"[^\\w]+\", \"_\", s.strip().lower(), flags=re.UNICODE)\n",
    "    s2 = re.sub(r\"_{2,}\", \"_\", s2).strip(\"_\")\n",
    "    return s2\n",
    "\n",
    "def find_col(candidates: List[str], patterns: List[str]) -> str | None:\n",
    "    for c in candidates:\n",
    "        cl = c.lower()\n",
    "        ok = True\n",
    "        for pat in patterns:\n",
    "            ors = pat.split(\"|\")\n",
    "            if not any(o in cl for o in ors):\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def quantiles_report(s: pd.Series, qs=(0.5, 0.9, 0.95, 0.99)) -> pd.Series:\n",
    "    qv = s.quantile(q=list(qs))\n",
    "    qv.index = [f\"q{int(q*100):02d}\" for q in qs]\n",
    "    return qv\n",
    "\n",
    "def savefig(path: Path):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=160)\n",
    "    print(f\"[FIG] salvo: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59b7d2",
   "metadata": {},
   "source": [
    "## üîç EDA do Arquivo Bruto\n",
    "\n",
    "Nesta se√ß√£o faremos:\n",
    "1. **Leitura segura** (encoding, separador, decimal).  \n",
    "2. **Shape, colunas, tipos, nulos, duplicatas**.  \n",
    "3. **Estat√≠sticas descritivas** (mediana, p95, p99) para entender caudas.  \n",
    "4. **Sanidade de chaves l√≥gicas**: (ano, uf, centil) sem duplicidades por registro.  \n",
    "5. **Distribui√ß√µes**:\n",
    "   - Histogramas de `rtb_soma_centil`, `bens_imoveis`, `dividas_onus`.  \n",
    "   - Scatterpairs para rela√ß√µes bivariadas.  \n",
    "6. **Zeros e ‚Äúaus√™ncias esperadas‚Äù**: bens ou d√≠vidas podem ter zeros; n√£o confundir com *missing*.  \n",
    "7. **Outliers**: avaliar se s√£o fen√¥meno real (alt√≠ssima concentra√ß√£o no topo) ‚Üí provavelmente **n√£o remover**, apenas documentar e considerar **log-transform** opcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = read_csv_br(DATA_RAW)\n",
    "\n",
    "print(\"\\n# VIS√ÉO GERAL\")\n",
    "print(\"shape:\", df_raw.shape)\n",
    "display(df_raw.head(10))\n",
    "\n",
    "print(\"\\n# COLUNAS\")\n",
    "print(list(df_raw.columns))\n",
    "\n",
    "print(\"\\n# TIPOS\")\n",
    "display(df_raw.dtypes)\n",
    "\n",
    "print(\"\\n# NULOS (%)\")\n",
    "display((df_raw.isna().mean() * 100).round(2).sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n# Duplicatas (linhas id√™nticas):\", df_raw.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_raw.columns)\n",
    "\n",
    "col_ano    = find_col(cols, [\"ano\", \"calendario|calend√°rio\"])\n",
    "col_uf     = find_col(cols, [\"ente|uf|federativo\"])\n",
    "col_centil = find_col(cols, [\"centil\"])\n",
    "\n",
    "col_rtb_soma   = find_col(cols, [\"rendimentos|rtb\", \"soma|somatorio|somat√≥rio\"])\n",
    "col_bens_imov  = find_col(cols, [\"bens|direitos\", \"imoveis|im√≥veis\"])\n",
    "col_dividas    = find_col(cols, [\"dividas|d√≠vidas\", \"onus|√¥nus\"])\n",
    "\n",
    "mapping = {\n",
    "    col_ano: \"ano\",\n",
    "    col_uf: \"uf\",\n",
    "    col_centil: \"centil\",\n",
    "    col_rtb_soma: \"rtb_soma_centil\",\n",
    "    col_bens_imov: \"bens_imoveis\",\n",
    "    col_dividas: \"dividas_onus\",\n",
    "}\n",
    "\n",
    "print(\"# MAPEAMENTO PROPOSTO\")\n",
    "display(mapping)\n",
    "\n",
    "missing_keys = [k for k in mapping if k is None]\n",
    "if missing_keys:\n",
    "    raise ValueError(\"N√£o consegui detectar automaticamente algumas colunas. Revise os padr√µes desta c√©lula e rode novamente.\")\n",
    "\n",
    "df = df_raw.rename(columns={k: v for k, v in mapping.items()})\n",
    "df.columns = [snake(c) for c in df.columns]\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c580124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tipagem robusta ===\n",
    "df[\"ano\"] = (\n",
    "    df[\"ano\"].astype(str).str.extract(r\"(\\d{4})\", expand=False)\n",
    "      .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "      .astype(\"Int64\")\n",
    ")\n",
    "\n",
    "centil_raw = (\n",
    "    df[\"centil\"]\n",
    "      .astype(str)\n",
    "      .str.replace(\",\", \".\", regex=False)\n",
    "      .str.extract(r\"(\\d+(?:\\.\\d+)?)\", expand=False)\n",
    ")\n",
    "df[\"centil\"] = pd.to_numeric(centil_raw, errors=\"coerce\")\n",
    "\n",
    "for c in [\"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"])\n",
    "\n",
    "mask_centil = (df[\"centil\"] >= 1) & (df[\"centil\"] <= 100)\n",
    "rem_out = (~mask_centil).sum()\n",
    "if rem_out:\n",
    "    print(f\"[INFO] Removendo {rem_out} linhas com centil fora de [1,100]\")\n",
    "df = df[mask_centil].copy()\n",
    "\n",
    "dup = df.duplicated(subset=[\"ano\", \"uf\", \"centil\"]).sum()\n",
    "print(\"Duplicidades em (ano, uf, centil):\", dup)\n",
    "\n",
    "print(\"Shape ap√≥s limpeza b√°sica:\", df.shape)\n",
    "display(df[[\"ano\", \"uf\", \"centil\", \"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0356068",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]\n",
    "display(df[num_cols].describe().T)\n",
    "\n",
    "qtab = pd.concat([quantiles_report(df[c]) for c in num_cols], axis=1).T\n",
    "qtab.columns = qtab.columns.str.upper()\n",
    "display(qtab)\n",
    "\n",
    "print(\"anos:\", sorted(df[\"ano\"].dropna().unique().tolist())[:10], \"...\")\n",
    "print(\"UFs (amostra):\", df[\"uf\"].dropna().unique()[:10])\n",
    "print(\"linhas totais:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21334d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3.6))\n",
    "for i,c in enumerate(num_cols, 1):\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.hist(df[c].dropna(), bins=40)\n",
    "    plt.title(c)\n",
    "    plt.xlabel(\"valor\")\n",
    "    plt.ylabel(\"freq\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pairs = [(\"rtb_soma_centil\",\"bens_imoveis\"),\n",
    "         (\"rtb_soma_centil\",\"dividas_onus\"),\n",
    "         (\"bens_imoveis\",\"dividas_onus\")]\n",
    "\n",
    "plt.figure(figsize=(12,3.6))\n",
    "for i,(x,y) in enumerate(pairs,1):\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.scatter(df[x], df[y], s=8, alpha=0.6)\n",
    "    plt.xlabel(x); plt.ylabel(y)\n",
    "    plt.title(f\"{x} vs {y}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for c in num_cols:\n",
    "    df[f\"log_{c}\"] = np.log1p(df[c].clip(lower=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f51509",
   "metadata": {},
   "source": [
    "## üß™ Estrat√©gia de Amostragem (300‚Äì500 linhas)\n",
    "\n",
    "**Princ√≠pio**: reprodutibilidade + representatividade.\n",
    "\n",
    "**Passos**:\n",
    "1. Escolher **um ano-base** (tipicamente o mais recente dispon√≠vel).  \n",
    "2. Calcular o total de linhas (UF √ó centis) e **estimar** quantos UFs e centis precisamos para cair entre **300‚Äì500**.  \n",
    "3. Estrat√©gias poss√≠veis (a definir ap√≥s ver o shape real):\n",
    "   - **E1 (recomendada)**: Fixar ano; **usar todos os UFs**; selecionar um **intervalo cont√≠nuo de centis** (ex.: 1‚Äì20, 30‚Äì60, 90‚Äì100) que d√™ ~300‚Äì500.  \n",
    "   - **E2**: Fixar ano; **amostrar UFs** (estratificado por regi√£o) e usar **todos os centis** desses UFs.  \n",
    "4. Fixar uma **seed** para qualquer amostragem aleat√≥ria.  \n",
    "5. Registrar a regra no `metadata.json`.\n",
    "\n",
    "> Justificativa did√°tica: manter **centis cont√≠guos** preserva estrutura da distribui√ß√£o e facilita interpretar clusters (baixa, m√©dia, alta renda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22699b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_year_base(data: pd.DataFrame) -> int:\n",
    "    anos = data[\"ano\"].dropna().astype(int)\n",
    "    year = int(anos.max())\n",
    "    print(f\"[ANO-BASE] Selecionado automaticamente: {year}\")\n",
    "    return year\n",
    "\n",
    "def sample_rows(data: pd.DataFrame, target_min: int = 300, target_max: int = 500) -> pd.DataFrame:\n",
    "    year = choose_year_base(data)\n",
    "    dfy = data.query(\"ano == @year\").copy()\n",
    "    possiveis_agregados = {\"brasil\", \"nacional\", \"todos\", \"agregado\"}\n",
    "    dfy[\"uf_lc\"] = dfy[\"uf\"].astype(str).str.lower()\n",
    "    dfy = dfy[~dfy[\"uf_lc\"].isin(possiveis_agregados)].drop(columns=[\"uf_lc\"])\n",
    "\n",
    "    n_uf = dfy[\"uf\"].nunique()\n",
    "    print(f\"[AMOSTRA] UFs distintos no ano {year}: {n_uf}\")\n",
    "\n",
    "    N_min = math.ceil(target_min / n_uf)\n",
    "    N_max = min(100, math.floor(target_max / n_uf))\n",
    "    N = max(1, min(N_max, max(N_min, 10)))\n",
    "    print(f\"[AMOSTRA] Intervalo de centis: 1..{N} (alvo {target_min}-{target_max})\")\n",
    "\n",
    "    df_sample = dfy[dfy[\"centil\"].between(1, N, inclusive=\"both\")].copy()\n",
    "    print(f\"[AMOSTRA] Linhas resultantes: {len(df_sample)}\")\n",
    "    return df_sample\n",
    "\n",
    "df_sample = sample_rows(df)\n",
    "display(df_sample.head())\n",
    "display(df_sample.tail())\n",
    "print(\"shape:\", df_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df_sample.duplicated(subset=[\"ano\", \"uf\", \"centil\"]).sum()\n",
    "print(\"Duplicidades (ano,uf,centil) na amostra:\", dups)\n",
    "\n",
    "print(\"Nulos nas vari√°veis selecionadas:\")\n",
    "display(df_sample[[\"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]].isna().sum())\n",
    "\n",
    "display(df_sample[[\"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68a8c8",
   "metadata": {},
   "source": [
    "## üßº Limpeza & Transforma√ß√µes\n",
    "\n",
    "1. **Padronizar nomes** de colunas para *snake_case*.  \n",
    "2. **Selecionar colunas**: `ano`, `uf`, `centil`, `rtb_soma_centil`, `bens_imoveis`, `dividas_onus`.  \n",
    "3. **Tipos corretos** (int/float); tratar decimal com v√≠rgula, se houver.  \n",
    "4. **Checagens de integridade**:\n",
    "   - `centil` ‚àà [1, 100]  \n",
    "   - Sem duplicidade para (ano, uf, centil) na amostra.  \n",
    "5. **Tratamento de escalas**:\n",
    "   - Manter valores em **R$ milh√µes** (consist√™ncia com a fonte).  \n",
    "   - Criar **vers√£o log-transform** para visualiza√ß√£o, se necess√°rio (`log1p`).  \n",
    "6. **Escalonamento (para o Notebook 02)**:\n",
    "   - Salvar **dados crus** e, opcionalmente, uma **c√≥pia escalada** (StandardScaler/MinMax) para K-Means.  \n",
    "   - A decis√£o final de escalonamento ser√° aplicada no Notebook 02; aqui apenas deixamos a fun√ß√£o e um preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684cce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_final = [\"ano\", \"uf\", \"centil\", \"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]\n",
    "df_out = df_sample[cols_final].copy()\n",
    "\n",
    "# Salvar\n",
    "DATA_PROCESSED.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(DATA_PROCESSED, index=False)\n",
    "print(f\"[SALVO] {DATA_PROCESSED} ({len(df_out)} linhas)\")\n",
    "\n",
    "# Metadados\n",
    "metadata = {\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"source_file\": str(DATA_RAW),\n",
    "    \"output_file\": str(DATA_PROCESSED),\n",
    "    \"year_base\": int(df_out[\"ano\"].dropna().max()) if len(df_out) else None,\n",
    "    \"sampling_rule\": \"ano=max; UFs=all (excl. agregados nacionais); centis=1..N tal que linhas entre 300-500\",\n",
    "    \"n_rows\": int(len(df_out)),\n",
    "    \"units\": {\n",
    "        \"rtb_soma_centil\": \"R$ milh√µes (somat√≥rio por centil)\",\n",
    "        \"bens_imoveis\": \"R$ milh√µes (somat√≥rio por UF-centil)\",\n",
    "        \"dividas_onus\": \"R$ milh√µes (somat√≥rio por UF-centil)\",\n",
    "    },\n",
    "    \"notes\": [\n",
    "        \"Colunas padronizadas para snake_case.\",\n",
    "        \"Zeros podem representar aus√™ncia real de bens/d√≠vidas.\",\n",
    "        \"EDA completa salva em reports/figures/.\",\n",
    "        \"Transforma√ß√µes log(1+x) usadas apenas para visualiza√ß√£o na EDA.\",\n",
    "    ],\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"authors\": [\n",
    "        \"Anderson de Matos Guimar√£es\",\n",
    "        \"Renan Ost\",\n",
    "        \"Gustavo Stefano Thomazinho\",\n",
    "    ],\n",
    "}\n",
    "import json\n",
    "with open(METADATA, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[SALVO] {METADATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X = df_out[[\"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"]].values\n",
    "\n",
    "sc_std = StandardScaler()\n",
    "X_std = sc_std.fit_transform(X)\n",
    "\n",
    "sc_mm = MinMaxScaler()\n",
    "X_mm = sc_mm.fit_transform(X)\n",
    "\n",
    "print(\"Preview StandardScaler (primeiras 5 linhas):\")\n",
    "print(pd.DataFrame(X_std, columns=[\"rtb_std\",\"imoveis_std\",\"dividas_std\"]).head())\n",
    "\n",
    "print(\"\\nPreview MinMaxScaler (primeiras 5 linhas):\")\n",
    "print(pd.DataFrame(X_mm, columns=[\"rtb_mm\",\"imoveis_mm\",\"dividas_mm\"]).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dde25e",
   "metadata": {},
   "source": [
    "## üíæ Persist√™ncia dos Resultados\n",
    "\n",
    "- **CSV final**: `data/processed/distribuicao-renda-3vars.csv`  \n",
    "  - Colunas: `ano, uf, centil, rtb_soma_centil, bens_imoveis, dividas_onus`  \n",
    "  - Somente linhas da **amostra definida**.  \n",
    "- **Metadados**: `data/processed/distribuicao-renda-3vars.metadata.json`  \n",
    "  - `created_at`, `source_file`, `year_base`, `sampling_rule`, `n_rows`, `units`, `notes`.  \n",
    "- **Imagens** (opcional): `reports/figures/eda_*`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7769a",
   "metadata": {},
   "source": [
    "## üß∞ Reprodutibilidade e Vers√£o\n",
    "\n",
    "- Scripts utilit√°rios em `src/utils.py` (fun√ß√µes de leitura, checagens, gr√°ficos r√°pidos).  \n",
    "- Fixar `RANDOM_SEED` no topo do notebook.  \n",
    "- Salvar `pip freeze` (opcional) em `requirements.txt` (j√° existe no repo).  \n",
    "- Comentar decis√µes no corpo do notebook para facilitar a corre√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774f7a7",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Limita√ß√µes & √âtica\n",
    "\n",
    "- Dados **agregados** por centis (n√£o individuais).  \n",
    "- Poss√≠vel **assimetria extrema** nos top centis (riqueza concentrada).  \n",
    "- ‚ÄúZero‚Äù em patrim√¥nio/d√≠vida pode indicar **aus√™ncia real**, n√£o erro.  \n",
    "- Interpreta√ß√µes devem ser **econ√¥micas** e **contextualizadas** (n√£o normativas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf89e7b",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Pr√≥ximos Passos (Notebook 02)\n",
    "\n",
    "- Escolha do **k** (Elbow, Silhouette).  \n",
    "- **K-Means** com dados escalados.  \n",
    "- **Gr√°fico 3D interativo** (Plotly) dos clusters.  \n",
    "- **Anima√ß√£o** (Forma√ß√£o dos clusters / frames por itera√ß√£o ou por *k*).  \n",
    "- Interpreta√ß√£o dos grupos e relato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ec73b9",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist (para eu mesmo)\n",
    "\n",
    "- [ ] CSV bruto carregado e validado  \n",
    "- [ ] Dicion√°rio de dados preenchido com nomes exatos  \n",
    "- [ ] Estrat√©gia de amostragem definida e aplicada  \n",
    "- [ ] 3 vari√°veis selecionadas e conferidas  \n",
    "- [ ] CSV tratado salvo + metadados gerados  \n",
    "- [ ] Gr√°ficos EDA salvos em `reports/figures/`  \n",
    "- [ ] Commit com mensagem padr√£o **conventional commits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ebd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = {\n",
    "    \"csv_tratado_existe\": DATA_PROCESSED.exists(),\n",
    "    \"metadata_existe\": METADATA.exists(),\n",
    "    \"linhas_entre_300_500\": (300 <= len(pd.read_csv(DATA_PROCESSED)) <= 500) if DATA_PROCESSED.exists() else False,\n",
    "    \"tem_colunas_certas\": (set(pd.read_csv(DATA_PROCESSED).columns) == {\"ano\", \"uf\", \"centil\", \"rtb_soma_centil\", \"bens_imoveis\", \"dividas_onus\"}) if DATA_PROCESSED.exists() else False,\n",
    "}\n",
    "print(checks)\n",
    "print(\"[OK] Todos os checks passaram.\" if all(checks.values()) else \"[ATEN√á√ÉO] Algum check falhou.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
